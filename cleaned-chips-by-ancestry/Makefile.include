## Lightning Auriga, 21 May 2020
## Shared pipeline for each ancestry in turn, pulled in through an include from a dummy makefile controller.
## Note that this means that this is executed from within the {ANCESTRY} directory, and output paths don't include that
## Ancestry is stored in "POPULATION_NAME"

include $(PROJECT_BASE_DIR)/Makefile.config

.PHONY: all all_chips
.SECONDARY:
.SECONDEXPANSION:
.DELETE_ON_ERROR:
all: all_chips

FINAL_CHIP_DATA := $(CHIP_FREEZE_INPUT_DIR)

## emits subject IDs for all subjects on a given platform matching a specified ancestry.
## intersects this with a chip famfile in case the ancestry data are a superset of the chip (this was relevant earlier in the cleaning process, but shouldn't be so now)
define ancestry_extract
sed 's/ /_/g' $(ANCESTRY_OUTPUT_DIR)/PLCO_$(2).graf_estimates.txt | awk '/\t$(1)$$/ {print $$1}' | sort | uniq | cat - $(FINAL_CHIP_DATA)/PLCO_$(2).fam | awk '{print $$1}' | sed 's/_//g' | sort | uniq -d
endef

## get all the platforms that have at least the minimum required number of subjects for cleaning (defaults to 10)
VALID_STUDIES := $(foreach STUDY,$(STUDIES),$(shell if [[ $$($(call ancestry_extract,$(POPULATION_NAME),$(STUDY)) | wc -l) -gt $(SAMPLE_SIZE_MIN) ]] ; then echo "$(STUDY)" ; fi))

## get all the platforms that have at least the minimum number of subjects for quasiparallelized IBS/IBD estimation
LARGE_STUDIES := $(foreach STUDY,$(STUDIES),$(shell if [[ $$($(call ancestry_extract,$(POPULATION_NAME),$(STUDY)) | wc -l) -gt $(SAMPLE_SIZE_LARGE) ]] ; then echo "$(STUDY)" ; fi))

## get the platforms that can just run in a single --genome IBS/IBD run, as the complement of the above
SMALL_STUDIES := $(filter-out $(LARGE_STUDIES),$(VALID_STUDIES))

## build target suffixes based on the set number of splits per quasiparallelized --genome platform
LARGE_STUDY_SUFFIXES := $(patsubst %,.genome.%.gz,$(shell seq 1 $(GENOME_GZ_JOB_SPLIT)))

## all targets are: IBS/IBD estimates; autosomal genomes without heterozygosity outliers; within-cleaned-platform-ancestry-subset GRAF relatedness estimates; PCA results
all_chips: $(patsubst %,%.step5.ibs-normal.genome.gz,$(SMALL_STUDIES)) $(patsubst %,%.step5.ibs-split.genome.gz,$(LARGE_STUDIES)) $(patsubst %,%.nohet.autosomes.bed,$(VALID_STUDIES)) $(patsubst %,%.graf_relatedness.txt,$(VALID_STUDIES)) $(patsubst %,%.step7.evec.success,$(VALID_STUDIES))

## patterns:
##    output: {CHIP}.graf_relatedness.txt
##    input:  {CHIP}.fpg
## Notes: this duplicates content from the relatedness pipeline
%.graf_relatedness.txt: %.fpg
	-$(GRAF_EXECUTABLE) -geno $< -out $@

## patterns:
##    output: {CHIP}.fpg
##    input:  {CHIP}.rsids.bed
## Notes: this duplicates content from the relatedness pipeline
%.fpg: %.rsids.bed
	-$(GRAF_EXECUTABLE) -exfp $(subst .bed,,$<) -out $@ -type 4

## patterns:
##    output: {CHIP}.rsids.bed (and bim, and fam)
##    input:  {CHIP}.nohet.autosomes.bed
##    input:  GRAF.extract
##    input:  GRAF.update_names
## Notes: this duplicates content from the relatedness pipeline
%.rsids.bed: %.nohet.autosomes.bed GRAF.extract GRAF.update_names
	$(PLINK19) --bfile $(subst .bed,,$<) --extract $(word 2,$^) --update-name $(word 3,$^) --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: GRAF.extract
##    input:  {GRAF_backend_bimfile}
## Notes: this duplicates content from the relatedness pipeline
GRAF.extract: $(GRAF_1KG_VARIANT_BIMFILE)
	awk '{print $$2}' $< > $@

## patterns:
##    output: GRAF.update_names
##    input:  {GRAF_backend_bimfile}
## Notes: this duplicates content from the relatedness pipeline
GRAF.update_names: $(GRAF_1KG_VARIANT_BIMFILE)
	awk '{print $$1":"$$4"\t"$$2}' $< > $@



## patterns:
##    output: {CHIP}.nohet.autosomes.bed (and bim, amd fam)
##    input:  {CHIP}.step1.maf.geno.hwe.bed
##    input:  {CHIP}.step4.het.remove
## Notes: this applies the heterozygosity filter from step4. Note that in practice in the cleaned dataset, the remove
## file typically contains no people as it was used to flag iteratively removed subjects upstream
%.nohet.autosomes.bed: %.step1.maf.geno.hwe.bed %.step4.het.remove
	$(PLINK19) --bfile $(subst .bed,,$<) --remove $(word 2,$^) --autosome --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: {CHIP}.ancestry.keep
##    input:  {ANCESTRY_PIPELINE}/PLCO_{CHIP}.graf_estimates.txt
## Notes: assumes the ancestry pipeline has already been run; top level makefile controls this behavior
%.ancestry.keep: $(ANCESTRY_OUTPUT_DIR)/PLCO_$$(subst .ancestry.keep,,$$@).graf_estimates.txt
	$(call ancestry_extract,$(POPULATION_NAME),$(subst .ancestry.keep,,$@)) | awk -F"\t" '{print $$1"\t"$$1}' > $@

## patterns:
##    output: {CHIP}.step0.ancestry.bed (and bim, and fam)
##    input:  {CHIP_FREEZE}/PLCO_{CHIP}.bed
##    input:  {CHIP}.ancestry.keep
## Notes: get subjects from this platform of the currently processed ancestry
%.step0.ancestry.bed: $(FINAL_CHIP_DATA)/PLCO_%.bed %.ancestry.keep
	$(PLINK19) --bfile $(subst .bed,,$<) --keep $(word 2,$^) --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: {CHIP}.step1.maf.geno.hwe.bed (and bim, and fam)
##    input:  {CHIP}.step0.ancestry.bed
## Notes: apply MAF, HWE, genotype missingness filters. Pretty stringent relative to CGR defaults; likely too stringent for admixed pops
%.step1.maf.geno.hwe.bed: %.step0.ancestry.bed
	$(PLINK19) --bfile $(subst .bed,,$<) --maf 0.01 --geno 0.02 --hwe 0.001 --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: {CHIP}.step2.pruning.prune.in
##    input:  {CHIP}.step1.maf.geno.hwe.bed
## Notes: compute variant inclusion list from first pass LD pruning
%.step2.pruning.prune.in: %.step1.maf.geno.hwe.bed
	$(PLINK19) --bfile $(subst .bed,,$<) --indep 50 5 2 --out $(subst .prune.in,,$@)

## patterns:
##    output: {CHIP}.step2.pruning.bed (and bim, and fam)
##    input:  {CHIP}.step1.maf.geno.hwe.bed
##    input:  {CHIP}.step2.pruning.prune.in
## Notes: apply variant inclusion list from first pass LD pruning
%.step2.pruning.bed: %.step1.maf.geno.hwe.bed $$(subst .bed,.prune.in,$$@)
	$(PLINK19) --bfile $(subst .bed,,$<) --extract $(word 2,$^) --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: {CHIP}.step3.pruning.prune.in
##    input:  {CHIP}.step2.pruning.bed
## Notes: compute variant inclusion list from second pass LD pruning
%.step3.pruning.prune.in: %.step2.pruning.bed
	$(PLINK19) --bfile $(subst .bed,,$<) --indep-pairwise 50 5 0.2 --out $(subst .prune.in,,$@)

## patterns:
##    output: {CHIP}.step3.pruning.bed (and bim, and fam)
##    input:  {CHIP}.step2.pruning.bed
##    input:  {CHIP}.step3.pruning.prune.in
## Notes: apply variant inclusion list from second pass LD pruning
%.step3.pruning.bed: %.step2.pruning.bed $$(subst .bed,.prune.in,$$@)
	$(PLINK19) --bfile $(subst .bed,,$<) --extract $(word 2,$^) --make-bed --out $(subst .bed,,$@)

## patterns:
##    output: {CHIP}.step4.het
##    input:  {CHIP}.step3.pruning.bed
## Notes: compute heterozygosity F statistics on LD pruned data
%.step4.het: %.step3.pruning.bed
	$(PLINK19) --bfile $(subst .bed,,$<) --het --out $(subst .het,,$@)

## patterns:
##    output: {CHIP}.step4.het.remove
##    input:  {CHIP}.step4.het
## Notes: generate plink-format remove list for subjects flagged as heterozygosity outliers.
## F statistic threshold is arbitrary, using |F| > 0.2 here by default
%.step4.het.remove: $$(subst .remove,,$$@)
	awk 'NR > 1 && sqrt($$6^2) > sqrt($(HET_F_MAX)^2) {print $$1"\t"$$1}' $< > $@ 

## patterns:
##    output: {CHIP}.step5.ibs-split.genome.{SPLIT-NUMBER}.gz
##    input:  {CHIP}.step3.pruning.bed
##    input:  {CHIP}.step4.het.remove
## Notes: generates rules for quasiparallelized plink --genome for each platform and split. Yes, this is hideous.
$(foreach platform,$(STUDIES),$(foreach subset,$(shell seq 1 $(GENOME_GZ_JOB_SPLIT)),$(platform).step5.ibs-split.genome.$(subset).gz)): $$(word 1,$$(subst .step5, ,$$@)).step3.pruning.bed $$(word 1,$$(subst .step5, ,$$@)).step4.het.remove
	$(PLINK19) --bfile $(subst .bed,,$<) --remove $(word 2,$^) --genome gz --min $(PIHAT_MIN) --parallel $(word 2,$(subst .genome., ,$(subst .gz,,$@))) $(GENOME_GZ_JOB_SPLIT) --out $(word 1,$(subst .ibs-split, ,$@)).ibs-split

## patterns:
##    output: {CHIP}.step5.ibs-split.genome.gz
##    input:  {CHIP}.step5.ibs-split.genome.{EACH-SPLIT-NUMBER}.gz
## Notes: merging function for combining quasiparallelized --genome runs. also effectively controls which studies have this applied to them
$(patsubst %,%.step5.ibs-split.genome.gz,$(LARGE_STUDIES)): $$(patsubst %,$$(subst .gz,,$$@).%.gz,$$(shell seq 1 $(GENOME_GZ_JOB_SPLIT)))
	gunzip -c $^ | gzip -c > $@

## patterns:
##    output: {CHIP}.step5.ibs-normal.genome.gz
##    input:  {CHIP}.step3.pruning.bed
##    input:  {CHIP}.step4.het.remove
## Notes: controller function for non-parallelized plink --genome for sufficiently small datasets
%.step5.ibs-normal.genome.gz: %.step3.pruning.bed %.step4.het.remove
	$(PLINK19) --bfile $(subst .bed,,$<) --remove $(word 2,$^) --genome gz --min $(PIHAT_MIN) --out $(subst .genome.gz,,$@)

## patterns:
##    output: {CHIP}.step7.evec.success
##    input:  {CHIP}.step6.bed
##    input:  {CHIP}.step6.snp
##    input:  {CHIP}.step6.ind
##    input:  {CHIP}.pca.par
##    input:  {CHIP}.pca.poplist
## Notes: run eigenstrat smartpca fastmode
%.step7.evec.success: %.step6.bed %.step6.snp %.step6.ind %.pca.par %.pca.poplist
	$(call qsub_handler,$(subst .success,,$@),$(SMARTPCA) -p $(word 4,$^))

## patterns:
##    output: {CHIP}.pca.par
##    input:  {CHIP}.step6.bed
##    input:  {CHIP}.step6.snp
##    input:  {CHIP}.step6.ind
##    input:  {CHIP}.pca.poplist
## Notes: generate smartpca parameter file. inputs are just to modify when it's rebuilt
%.pca.par: %.step6.bed %.step6.snp %.step6.ind %.pca.poplist
	echo -e "genotypename: $(subst .pca.par,,$@).step6.bed\nsnpname: $(subst .pca.par,,$@).step6.snp\nindivname: $(subst .pca.par,,$@).step6.ind\nevecoutname: $(subst .pca.par,,$@).step7.evec\naltnormstyle: NO\nnumoutevec: 10\nnumoutlieriter: 5\nnumoutlierevec: 2\noutliersigmathresh: 6.0\nqtmode: 0\nfastmode: 1\npoplist: $(subst .pca.par,,$@).pca.poplist" > $@

## patterns:
##    output: {CHIP}.pca.poplist
##    input:  {CHIP}.step6.bed
##    input:  {CHIP}.step6.snp
##    input:  {CHIP}.step6.ind
## Notes: generate smartpca population summary list. inputs are just to modify when it's rebuilt
%.pca.poplist: %.step6.bed %.step6.snp %.step6.ind
	echo -e "case\ncontrol\nunknown" > $@

## patterns:
##    output: {CHIP}.step6.snp
##    input:  {CHIP}.step6.bed (really bim)
## Notes: eigenstrat/smartpca formats are weird, so reformat bimfile accordingly.
## input is .bed due to how plink reformatting commands are tracked.
%.step6.snp: %.step6.bed
	awk '{print $$2"\t"$$1"\t"$$4/100000000"\t"$$4"\t"$$5"\t"$$6}' $(subst .bed,.bim,$<) > $@

## patterns:
##    output: {CHIP}.step6.ind
##    input:  {CHIP}.step6.bed (really fam)
## Notes: eigenstrat/smartpca formats are weird, so reformat bimfile according.
## input is .bed due to how plink reformatting commands are tracked.
%.step6.ind: %.step6.bed
	awk '$$5 == 2 {$$5 = "F"} ; $$5 == 1 {$$5 = "M"} ; $$6 == 2 {print $$1" "$$5" case"} ; $$6 == 1 {print $$1" "$$5" control"} ; $$6 != 1 && $$6 != 2 {print $$1" "$$5" unknown"}' $(subst .bed,.fam,$<) > $@

## patterns:
##    output: {CHIP}.step6.bed (and bim, and fam)
##    input:  {CHIP}.step3.pruning.bed
##    input:  {CHIP}.step4.het.remove
## Notes: remove heterozygosity outliers and prepare for smartpca.
%.step6.bed: %.step3.pruning.bed %.step4.het.remove
	$(PLINK19) --bfile $(subst .bed,,$<) --remove $(word 2,$^) --make-bed --out $(subst .bed,,$@)
